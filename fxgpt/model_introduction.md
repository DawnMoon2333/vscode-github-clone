# 公告

新用户注册即送0.2美元额度，本站购买汇率：3.5人民币兑换1美元（立省50%！），充值有10%的服务费  

登录后点击左侧聊天，点击确认自动填入预置设置，选择要使用的模型即可开始对话  

或者点击令牌-右侧聊天在独立的网页中对话  

本站微信公众号，关注公众号不迷路  

![公众号](https://image.fxgpt.site/i/12ae5fc1-d126-453d-9f2a-accc3ac9de9e.jpg)

# 模型介绍

## 省流

| 模型名 | 擅长领域/优点 | 最大上下文 | 最大回复 |
| :-: |  :-: |  :-: |  :-: |
| o1-preview | 推理，深度思考，能力最强 | 128k | \\ |
| o1-mini | 推理，轻量级 | 128k | \\ |
| gpt-4o | 多模态，旗舰，综合能力强 | 128k | \\ |
| gpt-4o-mini | 多模态，轻量级，高性价比 | 128k | \\ |
| gpt-4 | 综合能力强 | 8k | 8k |
| gpt-3.5-turbo | 响应速度快，综合能力强 | 4k | 4k |
| claude-3-5 | 多模态，最智能的模型 | 200k | 8k |
| claude-3 | 多模态，擅长写作和复杂任务 | 200k | 4k |
| moonshot-8k | 综合能力强 | 8k | 4k |
| moonshot-32k | 综合能力强 | 32k | 4k |
| moonshot-128k | 综合能力强 | 128k | 4k |
| qwen-turbo | 响应速度快，适合简单任务 | 128k | 8k |
| qwen-plus | 平衡质量和速度，综合能力强 | 128k | 8k |
| qwen-max | 旗舰，能力最强 | 32k | 8k |
| qwen-long | 对长文本优化 | 1000k | 6k |
| glm-plus | 旗舰，能力最强 | 128k | 4k |
| glm-airx | 轻量级，响应速度快 | 8k | 4k |
| glm-long | 对长文本优化 | 1000k | 4k |

<br/>

## o1-preview和o1-mini

OpenAI于2024年09月12日推出的全新推理模型o1，在请求之后会有10秒左右的思考时间，然后才开始回复。  

o1-preview和o1-mini在逻辑推理、数学、物理及代码生成领域实现了显著提升，展现出优于前代（如gpt-4、gpt-4o）的自我修正与策略探索能力，模仿人类思维模式，确保了解决方案的高效与精确。

o1-preview的能力更强，可以进行深度思考，o1-mini的请求速度更快且成本更低。  

## gpt-4o

OpenAI的旗舰模型，可以实时推理音频、视觉和文本。

是迈向更自然的人机交互的一步——它接受文本、音频和图像的任意组合作为输入，并生成文本、音频和图像输出的任意组合。

它可以在短短 232 毫秒内响应音频输入，平均为 320 毫秒，与现有模型相比，GPT-4o 在视觉和音频理解方面尤其出色。  

## gpt-4o-mini

GPT-4o-mini是平衡了性能与成本的小参数模型，能力范围介于gpt-3.5与gpt-4o之间，为用户提供了高性价比的选择。

<br/>

## gpt-4

OpenAI官方GPT4系列。知识库截止于2021年，最大回复8k，价格适中，具有中等参数。  

## gpt-3-turbo

作为OpenAI的明星产品，gpt-3-turbo是GPT3.5系列中的高速模型，最大回复长度4k tokens，综合能力强，是目前使用最广泛的文本模型.

<br/>

## claude-3.5 和 claude-3

Anthropic公司Claude系列模型的最新成员。  

claude-3-5-sonnet在智能和速度之间取得平衡，特别适合企业工作负载。在部分领域已经超越了gpt-4系列模型。最大上下文200k，最大回复8k。 

claude-3-opus是Anthropic目前最强的语言模型，适合处理高度复杂的问题。在很多领域已经超越了gpt-4系列模型。最大上下文200k，最大回复4k。

<br/>

## Qwen 通义千问

Qwen是来自阿里云的通义千问系列国产大模型。  

### Qwen-Plus

专注于多模态数据处理，结合图像与文本理解与生成，广泛应用于图像描述、问答等任务，速度、效果与成本达到良好平衡，最大上下文130k。  

### Qwen-Turbo

优化了响应速度，能够在短时间内生成高质量的回答，适合简单任务，速度快、成本低。  

### Qwen-Max

Qwen系列中的最强模型，具有强大的语言处理能力和推理能力，能够处理更复杂的语言任务，如长文本生成、多轮对话等。   

### Qwen-Long

专为大型文档设计，优化处理千万字级别的文本分析，最大上下文1000k，满足大规模数据分析需求。  

<br/>

## Moonshot

来自“月之暗面”的Moonshot系列，以处理20万汉字的超长文本著称，借助无损长程注意力机制和中文专项优化，有效应对复杂文本分析、长文档摘要等高级需求，提供8k、32k、128k不同最大上下文长度选项，突破了传统模型的长文本处理瓶颈。 

<br/>

## GLM 智谱大模型

来自清华大学的GLM-4系列国产大模型。  

### GLM-4-Plus

GLM-4-Plus是GLM-4系列中的高智能旗舰，性能全面提升，长文本和复杂任务能力显著增强，具有更强的语言处理能力，适用于处理复杂文本任务，如长文本生成、多轮对话等，最长上下文128k。  

### GLM-4-Long

GLM-4-Long是GLM-4系列中的长文本处理专家，优化了处理长文本的能力，适用于处理大型文档、长文本分析等任务，最长上下文1000k。  

### GLM-4-AirX

GLM-4-AirX是GLM-4系列中的轻量级模型，具有更快的响应速度和更低的成本，适用于处理简单任务，最长上下文8k。